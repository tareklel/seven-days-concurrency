Day 1
Usually when I grasp a concept I really enjoy if I don't practice it for a specific period, I'll forget it. 
So I've decided to talk about concurrency in programming for 7 days for it to stick. Why is concurrency amazing? 
Below are two pieces of code that do the same thing, read webpages, but one take 0.9-1.6 seconds to run while the other takes 5-6 seconds to run. 
The first one runs 5 times as fast because of concurrency, a significant performance boost. 
How was this achieved? 
In the first piece of code, multiple execution flows called threads execute functions to read websites 
concurrently without having to wait for previous functions to complete the entirety of their task. 
Since they're not waiting on external events to complete, such as waiting for a response from a website, a new task can start and exevute code in the meantime. 
So overall more gets done when waiting time is put to good use! Tomorrow I'll talk about where concurrency can go wrong.

#7daysofconcurrency #day1

Day 2 of 7 Days of Concurrency: Running threads concurrently speeds up performance, but this gain in performance comes with its own set of risks. 
Consider having a bunch of threads accessing and changing a block of data concurrently. 
Because the thread scheduling algorithm can swap between threads at any time, 
there is a chance that the program produces undesirable results such as when a thread reads data before another thread completes writing changes to that data.  
This is known as race conditions. Therefore threads need to let each other know that they are still going at a task and that other threads should wait. 
Once solution to this are semaphores, an abstract data type that can be used for signaling whether a resource can be accessed. 
In the below code multiple-threads are used to increment values to a global variable, 
semaphores are acquired while a thread is incrementing to the variable and then released so that other threads can start incrementing. 
Unfortunately semaphores do not solve all of the challenges that come with concurrency and they even create new ones. 
Tomorrow we will discuss other ways to safely exchange data between threads.

try it out yourself here:

https://lnkd.in/dTVUbCD

#7daysofconcurrency #day2 #programming #python

Day 3 of 7 Days of Concurrency:  Let's say you have a group of threads and you want them to exchange data safely amongst each other. 
An effective way to do this is by utilizing a queue object with locks, 
which conveniently enough exists as a Queue class in Python in the queue library. 
Threads can get and put data into the queue which can then be consumed by other threads. 
In addition to data you can pass other objects in the queue. 
An example would be a sentinel passed on to signal the end of a job. 
In the code below if a thread gets a sentinel from the queue it returns it to the queue and then stops. 
That way another thread can pick it up, and eventually all threads stop. 
These properties make queues attractive building blocks for distributed systems. 
According to the Python Cookbook (O'Reilly) communicating with queues often leads to designs that can be scaled up to other 
kinds of message-based communication patterns later on without any drastic changes to the underlying architecture. 
Tomorrow let's talk about a common problem in concurrent programming: deadlocks.
try it out yourself here:
https://lnkd.in/dTVUbCD
#7daysofconcurrency #day3 #programming #python

Day 4 of 7 Days of Concurrency: A common problem that needs to be addressed in concurrency is deadlock. This is a possibility when the threads in your program need to 
acquire more than one lock at a time to run. Let's say thread A & thread B need both locks 1 & 2 to run. If a thread grabs a lock it will continuously try to acquire 
the other lock and then execute a task and release both. When the program runs, if thread A acquires lock 1 and thread B acquires lock 2 neither have both locks to 
execute and release. Both threads will just hang around waiting and the program will freeze. A surprisingly simple solution to solve this is to impose an ordering rule 
so that multiple locks can only be acquired in ascending order. When thread A acquires lock 1, thread B waits until thread A releases lock 1 to acquire it and only 
then acquires lock 2 when it is released. Now the two threads can work happily ever after.

try it out yourself here:

https://lnkd.in/dTVUbCD

#7daysofconcurrency #day4 #programming #python
